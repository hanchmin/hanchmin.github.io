<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Hancheng Min </title> <meta name="author" content="Hancheng Min"> <meta name="description" content="Hancheng Min's personal website "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a7b9346409f983912ffd90ed5bf7aca8"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/university_shield_small_blue.png?5eea9293dfd5ff7d7789a5d23441bc88"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="hanchmin.github.io/"> <script src="/assets/js/theme.js?1bdf01d54938613f3a7fc47c8da5491e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/updates/">Updates </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span style="color: #990000 ;font-weight:bold">Hancheng</span> Min </h1> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile-1400.webp"></source> <img src="/assets/img/profile.png" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" max-width="10rem" alt="profile.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <div class="author-details"> <p> <strong>Postdoctoral Researcher,</strong> <em>Electrical and Systems Engineering, University of Pennsylvania</em><br> <strong>Email: </strong><em>hanchmin [at] seas [dot] upenn [dot] edu</em> </p> <p class="meta-links"> <a href="/assets/pdf/cv_hm.pdf" target="_blank">[CV]</a> / <a href="https://scholar.google.com/citations?user=XgQjPZIAAAAJ&amp;hl=en" target="_blank" rel="external nofollow noopener">[Google Scholar]</a> </p> </div> <div id="bio-content"> <p>I am a Postdoc Researcher at <a href="https://ideas.seas.upenn.edu/" rel="external nofollow noopener" target="_blank">Center for Innovation in Data Engineering and Science (IDEAS)</a>, University of Pennsylvania, advised by <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">Prof. René Vidal</a>. My research centers around building mathematical principles that facilitates the interplay between machine learning and dynamical systems. Recently, I am mainly interested in analyzing gradient-based optimization algorithms on overparametrized neural networks from a dynamical system perspective.</p> <span class="toggle-indicator-container"> <button id="toggle-bio-button" class="btn btn-link toggle-indicator"> More <i class="fas fa-chevron-down"></i> </button> </span> <div id="more-bio" style="display: none;"> <p>Prior to entering Penn, I received Ph.D. degree from Johns Hopkins University, where I am fortunate to be advised by <a href="http://mallada.ece.jhu.edu" rel="external nofollow noopener" target="_blank">Prof. Enrique Mallada</a> and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">Prof. René Vidal</a>. Before Hopkins, I received Master’s degree in Systems Engineering from University of Pennsylvannia and Bachelor’s degree in Automation from Tongji Univerisity, Shanghai.</p> </div> </div> </div> <div class="content-section card-style"> <h2>Recent Updates</h2> <div class="news"> <div class="news-list"> <div class="news-item" style="margin-bottom: 10px;"> [<strong>Jun, 25, 2025</strong>] Our paper <i>Voyaging into Unbounded Dynamic Scenes from a Single View</i> is accepted to <strong>ICCV 2025</strong> ! </div> <div class="news-item" style="margin-bottom: 10px;"> [<strong>May, 01, 2025</strong>] Our paper <i>Gradient Flow Provably Learns Robust Classifiers for Orthonormal GMMs</i> is accepted to <strong>ICML 2025</strong> ! See you in Vancouver! </div> <div class="news-item" style="margin-bottom: 10px;"> [<strong>Apr, 18, 2025</strong>] Our paper <i>A Local Polyak-Łojasiewicz and Descent Lemma of Gradient Descent For Overparametrized Linear Models</i> is accepted to <strong>TMLR</strong> ! </div> <div class="news-item" style="margin-bottom: 10px;"> [<strong>Feb, 26, 2025</strong>] Our paper <i>Concept Lancet: Decomposing and Transplanting Representations for Diffusion-Based Image Editing</i> is accepted to <strong>CVPR 2025</strong> ! </div> <div class="news-item" style="margin-bottom: 10px;"> [<strong>Jan, 22, 2025</strong>] Our paper <i>Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization</i> is accepted to <strong>AISTATS 2025</strong> ! </div> </div> <div style="text-align: left;"> <a href="/update/" style="color: inherit;">and more...</a> </div> </div> </div> <div class="content-section card-style"> <h2>Recent publications</h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="tdlmv2025iccv" class="col-sm-10"> <div class="title">Voyaging into Unbounded Dynamic Scenes from a Single View</div> <div class="author"> <a href="https://tianfr.github.io/" rel="external nofollow noopener" target="_blank">F. Tian</a>, <a href="https://tianjiaoding.com/" rel="external nofollow noopener" target="_blank">T. Ding</a>, <a href="https://peterljq.github.io/" rel="external nofollow noopener" target="_blank">J. Luo</a>, <em>H. Min</em>, and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a> </div> <div class="periodical"> <span style="font-style: italic;">International Conference on Computer Vision (ICCV)</span>, 2025 <span class="links" style="display: inline-block; margin-left: 10px;"> </span> </div> <div class="periodical"> to appear </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/robust_gmm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/robust_gmm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/robust_gmm-1400.webp"></source> <img src="/assets/img/publication_preview/robust_gmm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="robust_gmm.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mv2025icml" class="col-sm-10"> <div class="title">Gradient Flow Provably Learns Robust Classifiers for Orthonormal GMMs</div> <div class="author"> <em>H. Min</em>, and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a> </div> <div class="periodical"> <span style="font-style: italic;">International Conference on Machine Learning (ICML)</span>, Jul 2025 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> </span> <div class="abstract hidden"> <p>Deep learning-based classifiers are known to be vulnerable to adversarial attacks. Existing methods for defending against such attacks require adding a defense mechanism or modifying the learning procedure (e.g., by adding adversarial examples). This paper shows that for certain data distributions one can learn a provably robust classifier using standard learning methods and without adding a defense mechanism. More specifically, this paper addresses the problem of finding a robust classifier for a binary classification problem in which the data comes from an isotropic mixture of Gaussians with orthonormal cluster centers. First, we characterize the largest \ell_2-attack any classifier can defend against while maintaining high accuracy, and show the existence of optimal robust classifiers achieving this maximum \ell_2-robustness. Next, we show that given data sampled from the orthonormal Gaussian mixture model, gradient flow on a two-layer network with a polynomial ReLU activation and without adversarial examples provably finds an optimal robust classifier.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mv2025icml</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gradient Flow Provably Learns Robust Classifiers for Orthonormal GMMs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Min, Hancheng and Vidal, Ren\'e}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning ({ICML})}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">recent</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/colan-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/colan-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/colan-1400.webp"></source> <img src="/assets/img/publication_preview/colan.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="colan.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ldcmcv2025cvpr" class="col-sm-10"> <div class="title">Concept Lancet: Image Editing with Compositional Representation Transplant</div> <div class="author"> <a href="https://peterljq.github.io/" rel="external nofollow noopener" target="_blank">J. Luo</a>, <a href="https://tianjiaoding.com/" rel="external nofollow noopener" target="_blank">T. Ding</a>, <a href="https://ryanchankh.github.io/" rel="external nofollow noopener" target="_blank">K. Chan</a>, <em>H. Min</em>, C. Callison-Burch, and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a> </div> <div class="periodical"> <span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, Jun 2025 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a href="http://arxiv.org/abs/2504.02828" class="btn btn-sm z-depth-1" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> <a href="/assets/pdf/LDCMCV2025CVPR.pdf" class="btn btn-sm z-depth-1" role="button">PDF</a> <a href="https://github.com/peterljq/Concept-Lancet" class="btn btn-sm z-depth-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://peterljq.github.io/project/colan/" class="btn btn-sm z-depth-1" role="button" rel="external nofollow noopener" target="_blank">Website</a> </span> <div class="abstract hidden"> <p>Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure (e.g., Cat -&gt; Dog, Sketch -&gt; Painting) by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose ConceptLancent (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts and phrases. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace, add, or remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan 150k, which contains diverse descriptions and scenarios of visual concepts and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ldcmcv2025cvpr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Concept Lancet: Image Editing with Compositional Representation Transplant}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Luo, Jinqi and Ding, Tianjiao and Chan, Kwan Ho Ryan and Min, Hancheng and Callison-Burch, Chris and Vidal, Ren\'e}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Computer Vision and Pattern Recognition ({CVPR})}</span><span class="p">,</span>
  <span class="na">recent</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/lora-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/lora-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/lora-1400.webp"></source> <img src="/assets/img/publication_preview/lora.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="lora.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xmlmtmv2025aistats" class="col-sm-10"> <div class="title">Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization</div> <div class="author"> Z. Xu, <em>H. Min</em>, <a href="https://peterljq.github.io/" rel="external nofollow noopener" target="_blank">J. Luo</a>, <a href="https://lemacdonald.github.io/" rel="external nofollow noopener" target="_blank">L. MacDonald</a>, S. Tarmoun, <a href="https://mallada.ece.jhu.edu/" rel="external nofollow noopener" target="_blank">E. Mallada</a>, and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a> </div> <div class="periodical"> <span style="font-style: italic;">International Conference on Artificial Intelligence and Statistics (AISTATS)</span>, Apr 2025 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a href="http://arxiv.org/abs/2503.06982" class="btn btn-sm z-depth-1" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> <a href="/assets/pdf/XMMLTMV2025AISTATS.pdf" class="btn btn-sm z-depth-1" role="button">PDF</a> </span> <div class="abstract hidden"> <p>Despite Low-Rank Adaptation’s (LoRA) empirical success in fine-tuning pretrained models, there is little theoretical understanding of how first-order methods with carefully crafted initialization adapt models to new tasks. In this work, we take the first step towards bridging this gap by theoretically analyzing the learning dynamics of LoRA for matrix factorization (MF) under gradient flow (GF), emphasizing the crucial role of initialization. For small initialization, we theoretically show that GF converges to a neighborhood of the optimal solution, with smaller initialization leading to lower final error. Our analysis shows that the final error is affected by the misalignment between the singular spaces of the model and the target matrix, and reducing the initialization scale improves alignment. To address this misalignment, we propose a spectral initialization for LoRA in MF and theoretically prove that GF with small spectral initialization can converge to the target matrix with arbitrary precision. Numerical experiments from MF and image classification validate our findings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xmlmtmv2025aistats</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Ziqing and Min, Hancheng and Luo, Jinqi and MacDonald, Lachlan Ewen and Tarmoun, Salma and Mallada, Enrique and Vidal, Ren\'e}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Artificial Intelligence and Statistics ({AISTATS})}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">recent</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> </ol> </div> </div> <div class="content-section card-style"> <h2><a href="/publications/" style="color: inherit;">Selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/robust_gmm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/robust_gmm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/robust_gmm-1400.webp"></source> <img src="/assets/img/publication_preview/robust_gmm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="robust_gmm.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mv2025icml" class="col-sm-10"> <div class="title">Gradient Flow Provably Learns Robust Classifiers for Orthonormal GMMs</div> <div class="author"> <em>H. Min</em>, and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a> </div> <div class="periodical"> <span style="font-style: italic;">International Conference on Machine Learning (ICML)</span>, Jul 2025 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> </span> <div class="abstract hidden"> <p>Deep learning-based classifiers are known to be vulnerable to adversarial attacks. Existing methods for defending against such attacks require adding a defense mechanism or modifying the learning procedure (e.g., by adding adversarial examples). This paper shows that for certain data distributions one can learn a provably robust classifier using standard learning methods and without adding a defense mechanism. More specifically, this paper addresses the problem of finding a robust classifier for a binary classification problem in which the data comes from an isotropic mixture of Gaussians with orthonormal cluster centers. First, we characterize the largest \ell_2-attack any classifier can defend against while maintaining high accuracy, and show the existence of optimal robust classifiers achieving this maximum \ell_2-robustness. Next, we show that given data sampled from the orthonormal Gaussian mixture model, gradient flow on a two-layer network with a polynomial ReLU activation and without adversarial examples provably finds an optimal robust classifier.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mv2025icml</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gradient Flow Provably Learns Robust Classifiers for Orthonormal GMMs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Min, Hancheng and Vidal, Ren\'e}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning ({ICML})}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">recent</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/coherence.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/coherence.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/coherence.gif-1400.webp"></source> <img src="/assets/img/publication_preview/coherence.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="coherence.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mpm2025aut" class="col-sm-10"> <div class="title">A Frequency Domain Analysis of Slow Coherency in Networked Systems</div> <div class="author"> <em>H. Min</em>, <a href="https://www.richardpates.com/" rel="external nofollow noopener" target="_blank">R. Pates</a>, and <a href="https://mallada.ece.jhu.edu/" rel="external nofollow noopener" target="_blank">E. Mallada</a> </div> <div class="periodical"> <span style="font-style: italic;">Automatica</span>, Jul 2025 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.08438" class="btn btn-sm z-depth-1" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> </span> <div class="abstract hidden"> <p>Network coherence generally refers to the emergence of simple aggregated dynamical behaviours, despite heterogeneity in the dynamics of the subsystems that constitute the network. In this paper, we develop a general frequency domain framework to analyze and quantify the level of network coherence that a system exhibits by relating coherence with a low-rank property of the system’s input-output response. More precisely, for a networked system with linear dynamics and coupling, we show that, as the network’s \empheffective algebraic connectivity grows, the system transfer matrix converges to a rank-one transfer matrix representing the coherent behavior. Interestingly, the non-zero eigenvalue of such a rank-one matrix is given by the harmonic mean of individual nodal dynamics, and we refer to it as the coherent dynamics. Our analysis unveils the frequency-dependent nature of coherence and a non-trivial interplay between dynamics and network topology. We further show that many networked systems can exhibit similar coherent behavior by establishing a concentration result in a setting with randomly chosen individual nodal dynamics.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">mpm2025aut</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Frequency Domain Analysis of Slow Coherency in Networked Systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Min, Hancheng and Pates, Richard and Mallada, Enrique}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Automatica}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{174}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{112184}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/dir_flow.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/dir_flow.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/dir_flow.gif-1400.webp"></source> <img src="/assets/img/publication_preview/dir_flow.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="dir_flow.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mmv2024iclr" class="col-sm-10"> <div class="title">Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization</div> <div class="author"> <em>H. Min</em>, <a href="https://mallada.ece.jhu.edu/" rel="external nofollow noopener" target="_blank">E. Mallada</a>, and <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a> </div> <div class="periodical"> <span style="font-style: italic;">International Conference on Learning Representations (ICLR)</span>, May 2024 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a href="http://arxiv.org/abs/2307.12851" class="btn btn-sm z-depth-1" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> <a href="/assets/pdf/MMV2024ICLR.pdf" class="btn btn-sm z-depth-1" role="button">PDF</a> <a href="/assets/posters/MMV2024ICLR.pdf" class="btn btn-sm z-depth-1" role="button">Poster</a> <a href="/assets/slides/MMV2024ICLR.pdf" class="btn btn-sm z-depth-1" role="button">Slides</a> </span> <div class="abstract hidden"> <p>This paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. We consider a training dataset with well-separated input vectors: Any pair of input data with the same label are positively correlated, and any pair with different labels are negatively correlated. Our analysis shows that, during the early phase of training, neurons in the first layer try to align with either the positive data or the negative data, depending on its corresponding weight on the second layer. A careful analysis of the neurons’ directional dynamics allows us to provide an \mathcalO(\frac\log n\sqrtμ) upper bound on the time it takes for all neurons to achieve good alignment with the input data, where n is the number of data points and μmeasures how well the data are separated. After the early alignment phase, the loss converges to zero at a \mathcalO(\frac1t) rate, and the weight matrix on the first layer is approximately low-rank. Numerical experiments on the MNIST dataset illustrate our theoretical findings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mmv2024iclr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Min, Hancheng and Mallada, Enrique and Vidal, Ren\'e}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations ({ICLR})}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-8}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/lin_conv-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/lin_conv-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/lin_conv-1400.webp"></source> <img src="/assets/img/publication_preview/lin_conv.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="lin_conv.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mvm2023icml" class="col-sm-10"> <div class="title">On the Convergence of Gradient Flow on Multi-layer Linear Models</div> <div class="author"> <em>H. Min</em>, <a href="http://vision.jhu.edu/rvidal.html" rel="external nofollow noopener" target="_blank">R. Vidal</a>, and <a href="https://mallada.ece.jhu.edu/" rel="external nofollow noopener" target="_blank">E. Mallada</a> </div> <div class="periodical"> <span style="font-style: italic;">International Conference on Machine Learning (ICML)</span>, Jul 2023 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> <a href="/assets/pdf/MVM2023ICML.pdf" class="btn btn-sm z-depth-1" role="button">PDF</a> <a href="/assets/posters/MVM2023ICML.pdf" class="btn btn-sm z-depth-1" role="button">Poster</a> <a href="/assets/slides/MVM2023ICML.pdf" class="btn btn-sm z-depth-1" role="button">Slides</a> </span> <div class="abstract hidden"> <p>In this paper, we analyze the convergence of gradient flow on a multi-layer linear model with a loss function of the form f(W_1W_2⋯W_L). We show that when f satisfies the gradient dominance property, proper weight initialization leads to exponential convergence of the gradient flow to a global minimum of the loss. Moreover, the convergence rate depends on two trajectory-specific quantities that are controlled by the weight initialization: the imbalance matrices, which measure the difference between the weights of adjacent layers, and the least singular value of the weight product W=W_1W_2⋯W_L. Our analysis exploits the fact that the gradient of the overparameterized loss can be written as the composition of the non-overparametrized gradient with a time-varying (weight-dependent) linear operator whose smallest eigenvalue controls the convergence rate. The key challenge we address is to derive a uniform lower bound for this time-varying eigenvalue that lead to improved rates for several multi-layer network models studied in the literature.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mvm2023icml</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Convergence of Gradient Flow on Multi-layer Linear Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Min, Hancheng and Vidal, Ren\'e and Mallada, Enrique}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning ({ICML})}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{24850--24887}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/safe_rl-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/safe_rl-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/safe_rl-1400.webp"></source> <img src="/assets/img/publication_preview/safe_rl.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="safe_rl.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cmbm2021tac" class="col-sm-10"> <div class="title">Learning to Act Safely with Limited Exposure and Almost Sure Certainty</div> <div class="author"> <a href="https://mallada.ece.jhu.edu/people/agustin-castellano/" rel="external nofollow noopener" target="_blank">A. Castellano</a>, <em>H. Min</em>, <a href="https://www.engineering.pitt.edu/people/faculty/juan-bazerque-giusto/" rel="external nofollow noopener" target="_blank">J. Bazerque</a>, and <a href="https://mallada.ece.jhu.edu/" rel="external nofollow noopener" target="_blank">E. Mallada</a> </div> <div class="periodical"> <span style="font-style: italic;">IEEE Transactions on Automatic Control (TAC)</span>, May 2023 <span class="links" style="display: inline-block; margin-left: 10px;"> <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-1" role="button">Bib</a> <a href="/assets/pdf/CMBM2023TAC.pdf" class="btn btn-sm z-depth-1" role="button">PDF</a> </span> <div class="abstract hidden"> <p>This paper aims to put forward the concept that learning to take safe actions in unknown environments, even with probability one guarantees, can be achieved without the need for an unbounded number of exploratory trials, provided that one is willing to navigate trade-offs between optimality, level of exposure to unsafe events, and the maximum detection time of unsafe actions. We illustrate this concept in two complementary settings. We first focus on the canonical multi-armed bandit problem and seek to study the intrinsic trade-offs of learning safety in the presence of uncertainty. Under mild assumptions on sufficient exploration, we provide an algorithm that provably detects all unsafe machines in an (expected) finite number of rounds. The analysis also unveils a trade-off between the number of rounds needed to secure the environment and the probability of discarding safe machines. We then consider the problem of finding optimal policies for a Markov Decision Process (MDP) with almost sure constraints. We show that the (action) value function satisfies a barrier-based decomposition which allows for the identification of feasible policies independently of the reward process. Using this decomposition, we develop a Barrier-learning algorithm, that identifies such unsafe state-action pairs in a finite expected number of steps. Our analysis further highlights a trade-off between the time lag for the underlying MDP necessary to detect unsafe actions, and the level of exposure to unsafe events. Simulations corroborate our theoretical findings, further illustrating the aforementioned trade-offs, and suggesting that safety constraints can further speed up the learning process.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cmbm2021tac</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning to Act Safely with Limited Exposure and Almost Sure Certainty}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Castellano, Agustin and Min, Hancheng and Bazerque, Juan and Mallada, Enrique}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Automatic Control ({TAC})}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{68}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2979-2994}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TAC.2023.3240925}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="periodical"> </div> <div class="badges"> </div> </div> </div> </li> </ol> </div> </div> </article> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("toggle-bio-button"),n=document.getElementById("more-bio"),t=document.querySelector(".toggle-indicator-container"),o=document.getElementById("bio-content");if(e&&n&&t&&o)if(""!==n.innerHTML.trim()){const i=o.querySelector("p");i?(i.appendChild(t),e.addEventListener("click",function(){"none"===n.style.display||""===n.style.display?(n.style.display="block",e.innerHTML='Less <i class="fas fa-chevron-up"></i>'):(n.style.display="none",e.innerHTML='More <i class="fas fa-chevron-down"></i>')}),t.style.display="inline-block"):t.style.display="none"}else t.style.display="none"});</script> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Hancheng Min. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>